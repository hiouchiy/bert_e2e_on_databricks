# Databricks notebook source
# MAGIC %md
# MAGIC # Hugging Face ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ™ãƒ¼ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡ãƒ¢ãƒ‡ãƒ«ã‚’ã‚µãƒ¼ãƒ“ãƒ³ã‚°ã™ã‚‹
# MAGIC ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€`tohoku-nlp/bert-base-japanese-v3`ã‚’ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ã—ãŸæ–‡ç« åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã‚’ã‚µãƒ¼ãƒ“ãƒ³ã‚°ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¨ã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã™ã€‚
# MAGIC
# MAGIC ## ã‚¯ãƒ©ã‚¹ã‚¿ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
# MAGIC ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€AWS ã® `g4dn.xlarge` ã‚„ Azure ã® `Standard_NC4as_T4_v3` ã®ã‚ˆã†ãªã‚·ãƒ³ã‚°ãƒ« GPU ã‚¯ãƒ©ã‚¹ã‚¿ã‚’æ¨å¥¨ã—ã¾ã™ã€‚ã‚·ãƒ³ã‚°ãƒ«ãƒã‚·ãƒ³ã‚¯ãƒ©ã‚¹ã‚¿ã®ä½œæˆ](https://docs.databricks.com/clusters/configure.html) ã¯ã€ãƒ‘ãƒ¼ã‚½ãƒŠãƒ«ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒˆãƒãƒªã‚·ãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã€ã‚¯ãƒ©ã‚¹ã‚¿ä½œæˆæ™‚ã« "Single Node" ã‚’é¸æŠã™ã‚‹ã“ã¨ã§å¯èƒ½ã§ã™ã€‚ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯Databricks Runtime ML GPUãƒãƒ¼ã‚¸ãƒ§ãƒ³14.3 LTSã§å‹•ä½œç¢ºèªã—ã¦ãŠã‚Šã¾ã™ã€‚
# MAGIC
# MAGIC Databricks Runtime ML ã«ã¯ `transformers` ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€[ğŸ¤—&nbsp;Datasets](https://huggingface.co/docs/datasets/index) ã¨ [ğŸ¤—&nbsp;Evaluate](https://huggingface.co/docs/evakyate/index)ã‚‚å¿…è¦ã§ã€ã“ã‚Œã‚‰ã¯ `%pip` ã‚’ä½¿ã£ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã¾ã™ã€‚

# COMMAND ----------

# MAGIC %md
# MAGIC # 0. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼è¨­å®š

# COMMAND ----------

# MAGIC %pip install datasets evaluate fugashi unidic-lite accelerate
# MAGIC %pip install databricks-sdk==0.12.0 mlflow[genai] --upgrade --q
# MAGIC dbutils.library.restartPython()

# COMMAND ----------

# DBTITLE 1,ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã®è¨­å®š
# MLFlow Trackingã«è¨˜éŒ²ã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«åï¼ˆã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆåï¼‰
model_artifact_path = "bert_model_ja"

# ã‚«ã‚¿ãƒ­ã‚°å
catalog_name = "hiroshi"

# ã‚¹ã‚­ãƒ¼ãƒå
schema_name = "temp"

# ãƒ¢ãƒ‡ãƒ«ãƒ¬ã‚¸ã‚¹ãƒˆãƒªãƒ¼ã«ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«å
registered_model_name = "bert_model_ja"

# ãƒ¢ãƒ‡ãƒ«ã‚’MLFLow Model Registerã¸ç™»éŒ²ã™ã‚‹éš›ã«åå‰ï¼ˆcatalog_name.schema_name.model_nameï¼‰
registered_model_full_path = f"{catalog_name}.{schema_name}.{registered_model_name}"

# ãƒ¢ãƒ‡ãƒ«ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã‚‹MLFlowå®Ÿé¨“ã®Run ID
run_id = "YOUR_RUN_ID"

# ã‚µãƒ¼ãƒ“ãƒ³ã‚°ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®åå‰
endpoint_name = 'bert-text-classification-endpoint'

# COMMAND ----------

# DBTITLE 1,ãƒ†ã‚¹ãƒˆç”¨æ–‡ç« ãƒ‡ãƒ¼ã‚¿ï¼ˆç”ŸæˆAIã§é©å½“ã«ä½œã£ãŸã‚‚ã®ï¼‰
# ãƒ†ã‚¹ãƒˆç”¨ã®æ–‡ç« ãƒ‡ãƒ¼ã‚¿
inputs = [
    """
ã‚ªãƒ¼ã‚·ãƒ£ãƒ³ã‚·ãƒ†ã‚£ã«æ‰€å±ã™ã‚‹ãƒã‚ªãƒ©ãƒ³ãƒ‰ä»£è¡¨FWã‚¢ãƒ¬ãƒƒã‚¯ã‚¹ãƒ»ã‚¹ã‚¿ãƒ¼ãƒãƒ³ãŒã€å…¨ä½“ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«å¾©å¸°ã—ãŸã€‚13æ—¥ã€ã‚¯ãƒ©ãƒ–å…¬å¼ã‚µã‚¤ãƒˆãŒä¼ãˆã¦ã„ã‚‹ã€‚
ã‚ªãƒ¼ã‚·ãƒ£ãƒ³ã‚·ãƒ†ã‚£ã‚’é›¢ã‚Œã€ãƒã‚ªãƒ©ãƒ³ãƒ‰ä»£è¡¨ã§ã®ãƒŸã‚¹ãƒ†ã‚£ãƒƒã‚¯ã‚³ãƒ³ãƒãƒãƒ³ãƒ„ã‚«ãƒƒãƒ—ã«å‚æˆ¦ã—ã¦ã„ãŸã‚¹ã‚¿ãƒ¼ãƒãƒ³ã¯ã€å…ˆæœˆ18æ—¥ã«è¡Œã‚ã‚ŒãŸç¬¬2ç¯€ã®ã‚µãƒ³ãƒ©ã‚¤ãƒˆä»£è¡¨æˆ¦ï¼ˆâ–³2ï¼2ï¼‰ã§å·¦å¤ªã‚‚ã‚‚è£ã‚’è² å‚·ã—ã¦ã—ã¾ã„ã€å‰åŠã‚¢ãƒ‡ã‚£ã‚·ãƒ§ãƒŠãƒ«ã‚¿ã‚¤ãƒ ã«é€”ä¸­äº¤ä»£ã‚’ä½™å„€ãªãã•ã‚Œã€ãƒãƒ¼ãƒ ã‚’é›¢è„±ã—ã¦ã‚ªãƒ¼ã‚·ãƒ£ãƒ³ã‚·ãƒ†ã‚£ã«å¾©å¸°ã—ã¦ã„ãŸã€‚
    """,
    """
M3ã‚·ãƒªãƒ¼ã‚ºã¯ã€8ã‚³ã‚¢ã®CPUã¨10ã‚³ã‚¢ã®GPUã‚’å‚™ãˆã€æœ€å¤§ã§24GBã®çµ±åˆãƒ¡ãƒ¢ãƒªã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚M3 Proãƒ¢ãƒ‡ãƒ«ã§ã¯ã€CPUã‚’æœ€å¤§12ã‚³ã‚¢ã€GPUã‚’æœ€å¤§18ã‚³ã‚¢ã¾ã§é¸æŠå¯èƒ½ã§ã€çµ±åˆãƒ¡ãƒ¢ãƒªã¯æœ€å¤§ã§36GBã§ã™ã€‚ä¸€æ–¹ã€M3 Maxã§ã¯CPUã‚’æœ€å¤§ã§16ã‚³ã‚¢ã€GPUã‚’æœ€å¤§ã§40ã‚³ã‚¢ã€çµ±åˆãƒ¡ãƒ¢ãƒªã‚’æœ€å¤§ã§128GBã¾ã§é¸æŠã§ãã¾ã™ã€‚
ã“ã‚Œã‚‰å…¨ãƒ¢ãƒ‡ãƒ«ã«å…±é€šã—ã¦ã€AV1ã‚³ãƒ¼ãƒ‡ãƒƒã‚¯ã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹å†…è”µãƒ¡ãƒ‡ã‚£ã‚¢ã‚¨ãƒ³ã‚¸ãƒ³ã‚’æ­è¼‰ã—ã¦ãŠã‚Šã€HEVCã€H.264ã€ProResãªã©ã®æ§˜ã€…ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å†ç”ŸãŒå¯èƒ½ã§ã™ã€‚ã•ã‚‰ã«ã€Dolby Visionã€HDR 10ã€HLGã¨ã„ã£ãŸé«˜ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãƒ¬ãƒ³ã‚¸ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«ã‚‚å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚
    """,
    """
ã€€ã—ã‹ã—ã€æ‹æ„›ã«ãŠã„ã¦å—å‹•çš„ãªå§¿å‹¢ã‹ã‚‰å§‹ã‚ã‚‹ã“ã¨ãŒã€æ¥½ã ã¨æ„Ÿã˜ã¦ã—ã¾ã†ã¨ã€é–¢ä¿‚ãŒå§‹ã¾ã£ã¦ã‹ã‚‰å¹³ç­‰ãªä¿¡é ¼é–¢ä¿‚ã‚’æ§‹ç¯‰ã™ã‚‹ã®ãŒé›£ã—ããªã‚ŠãŒã¡ã§ã™ã€‚ç”·æ€§ãŒãƒªãƒ¼ãƒ‰ã—ã€å¥³æ€§ãŒãã‚Œã«å¾“ã†ã¨ã„ã†é–¢ä¿‚ãŒå®šç€ã™ã‚‹ã¨ã€å¥³æ€§ã¯å¾ã€…ã«ã€Œå«Œã‚ã‚ŒãŸããªã„ã€ã¨ã„ã†æ€ã„ã‹ã‚‰è‡ªã‚‰ã®æ„è¦‹ã‚’è¿°ã¹ã«ãããªã‚Šã¾ã™ã€‚ãã—ã¦ã€å ´åˆã«ã‚ˆã£ã¦ã¯ã€ç”·æ€§ãŒæ”¯é…çš„ãªæ…‹åº¦ã‚’ã¨ã‚‹ã‚ˆã†ã«ãªã‚Šã€ãã®ã‚ˆã†ãªé–¢ä¿‚ã‹ã‚‰æŠœã‘å‡ºã™ã®ãŒå›°é›£ã«ãªã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã®ã§ã™ã€‚
    """,
    """
21ä¸–ç´€ãƒ”ã‚¯ãƒãƒ£ãƒ¼ã‚ºãŒã€äººæ°—SFã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€ãƒãƒ³ã‚¿ãƒ¼ã‚ºã€ã‚·ãƒªãƒ¼ã‚ºã®æ–°ä½œæ˜ ç”»ã€ãƒ€ãƒ¼ã‚¯ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆåŸé¡Œï¼‰ / Darkfieldã€ã®è£½ä½œã‚’é€²ã‚ã¦ã„ã‚‹ã¨ã€The Global Film Gazette ãªã©ãŒå ±ã˜ãŸã€‚
ã€€ç›£ç£ã¯å‰ä½œã€ãƒãƒ³ã‚¿ãƒ¼ã‚ºï¼šã‚¶ãƒ»ã‚¯ã‚¨ã‚¹ãƒˆã€ï¼ˆ2022ï¼‰ã¨åŒã˜ãã‚¸ãƒ§ãƒ³ãƒ»ãƒ‰ãƒ¼ãƒ´ã‚¡ãƒ¼ãŒå‹™ã‚ã‚‹ãŒã€åŒã‚µã‚¤ãƒˆã«ã‚ˆã‚‹ã¨ã€æ–°ä½œã¯ã€ã‚¶ãƒ»ã‚¯ã‚¨ã‚¹ãƒˆã€ã®ç¶šç·¨ã«ã¯ãªã‚‰ãªã„ã¨ã®ã“ã¨ã€‚è©³ç´°ã¯ä¸æ˜ã ãŒã€æœªæ¥ã‚’èˆå°ã«ã€ã€ã‚¶ãƒ»ã‚¯ã‚¨ã‚¹ãƒˆã€ã¨åŒã˜ãå¥³æ€§ãŒä¸»äººå…¬ã«ãªã‚‹ã€‚
    """
]

# COMMAND ----------

# MAGIC %md
# MAGIC # 1. ãƒ¢ãƒ‡ãƒ«ã‚’ã‚µãƒ¼ãƒ“ãƒ³ã‚°ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¨ã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤
# MAGIC ã“ã®æ“ä½œã¯GUIã‹ã‚‰ã‚‚å®Ÿæ–½å¯èƒ½ã§ã™ãŒã€å†ç¾æ€§ã®ç¢ºä¿ã®ãŸã‚ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®æ‰‹é †ã‚’è¨˜è¼‰ã—ã¾ã™ã€‚

# COMMAND ----------

# DBTITLE 1,MLFlow Trackingã«è¨˜éŒ²ã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’MLFlow Model Registryï¼ˆUnity Catalogï¼‰ã¸ç™»éŒ²
import mlflow
mlflow.set_registry_uri('databricks-uc')

result = mlflow.register_model(
    "runs:/"+run_id+f"/{model_artifact_path}",
    registered_model_full_path,
)

# COMMAND ----------

# DBTITLE 1,MLFlow Model Registryã¸ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ç‰¹å®šã®ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«Aliasã‚’è¨­å®š
from mlflow import MlflowClient
client = MlflowClient()

# ä¸Šè¨˜ã®ã‚»ãƒ«ã«ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹æ­£ã—ã„ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’é¸æŠ
client.set_registered_model_alias(
  name=registered_model_full_path, 
  alias="Champion", 
  version=result.version
)

# COMMAND ----------

# DBTITLE 1,Model Registryã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’é–¢æ•°ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦æ¨è«–å®Ÿè¡Œ
import mlflow
import pandas as pd
import torch
from numba import cuda

device = cuda.get_current_device()
device.reset()

# Model Registryã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
loaded_model = mlflow.pyfunc.load_model(
  f"models:/{registered_model_full_path}@Champion"
)

# ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦æ¨è«–å®Ÿè¡Œ
input_example = pd.DataFrame({"text": inputs})
response = loaded_model.predict(input_example)
response

# COMMAND ----------

# DBTITLE 1,ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒ‡ãƒ—ãƒ­ã‚¤ç”¨ã«ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã®URLã¨ä¸€æ™‚ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
databricks_url = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiUrl().getOrElse(None)
token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().getOrElse(None)

# COMMAND ----------

# DBTITLE 1,ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ãƒ‡ãƒ—ãƒ­ã‚¤
# ã‚µãƒ¼ãƒ“ãƒ³ã‚°ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ä½œæˆã¾ãŸã¯æ›´æ–°
from databricks.sdk import WorkspaceClient
from databricks.sdk.service.serving import EndpointCoreConfigInput, ServedModelInput

model_version = result  # mlflow.register_modelã®è¿”ã•ã‚ŒãŸçµæœ

serving_endpoint_name = endpoint_name
latest_model_version = model_version.version
model_name = model_version.name

w = WorkspaceClient()
endpoint_config = EndpointCoreConfigInput(
    name=serving_endpoint_name,
    served_models=[
        ServedModelInput(
            model_name=model_name,
            model_version=latest_model_version,
            workload_type="GPU_SMALL",
            workload_size="Small",
            scale_to_zero_enabled=False
        )
    ]
)

existing_endpoint = next(
    (e for e in w.serving_endpoints.list() if e.name == serving_endpoint_name), None
)
serving_endpoint_url = f"{databricks_url}/ml/endpoints/{serving_endpoint_name}"
if existing_endpoint == None:
    print(f"Creating the endpoint {serving_endpoint_url}, this will take a few minutes to package and deploy the endpoint...")
    w.serving_endpoints.create_and_wait(name=serving_endpoint_name, config=endpoint_config)
else:
    print(f"Updating the endpoint {serving_endpoint_url} to version {latest_model_version}, this will take a few minutes to package and deploy the endpoint...")
    w.serving_endpoints.update_config_and_wait(served_models=endpoint_config.served_models, name=serving_endpoint_name)
    
displayHTML(f'Your Model Endpoint Serving is now available. Open the <a href="/ml/endpoints/{serving_endpoint_name}">Model Serving Endpoint page</a> for more details.')

# COMMAND ----------

# DBTITLE 1,ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å©ã„ã¦ã¿ã‚‹
import mlflow.deployments
deploy_client = mlflow.deployments.get_deploy_client("databricks")

# ã‚«ã‚¹ã‚¿ãƒ Embeddingãƒ¢ãƒ‡ãƒ«
for i in range(10):
  response = deploy_client.predict(
    endpoint = endpoint_name, 
    inputs = {"inputs": inputs}
  )

print(response)

# COMMAND ----------

# DBTITLE 1,ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å‰Šé™¤
client.delete_endpoint(endpoint=endpoint_name)

# COMMAND ----------

# MAGIC %md
# MAGIC ## ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼
